{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_LwBzSZFjl2"
   },
   "source": [
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> <img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "INF-395 / 477 / 577 Tarea 1 Redes Neuronales Artificiales - 2020-1 </h1>\n",
    "\n",
    "<H3 align='center'> Integrantes: Kevin Lagos - Andrés Navarro </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "* Manipulaciones en tensorflow, keras, pandas y numpy\n",
    "* Redes Densas Feed Forward\n",
    "* Regularización y Dropout\n",
    "* Exploding & Vanishing Gradient\n",
    "* Skip Connections\n",
    "* Learn Rate Decay\n",
    "* Optimizadores\n",
    "* Redes Convolucionales\n",
    "* Image Data Augmentation\n",
    "* Interpretabilidad CNNs\n",
    "\n",
    "\n",
    "**Formalidades**  \n",
    "* Equipos de trabajo de 2 personas (*Ambos estudiantes deben estar preparados para presentar la tarea el día de la entrega*)\n",
    "* El entregable debe ser un _Jupyter Notebook_ incluyendo los códigos utilizados, los resultados, los gráficos realizados y comentarios. Debe seguir una estructura similar a un informe (se debe introducir los problemas a trabajar, presentar los resultados y discutirlos). Si lo prefiere puede entregar un _Jupyter Notebook_ por pregunta o uno para toda la tarea, con tal de que todos los entregables estén bien identificados y se encuentren en el mismo repositorio de _Github_.\n",
    "* Se debe preparar una presentación del trabajo realizado y sus hallazgos. El presentador será elegido aleatoriamente y deberá apoyarse en el _Jupyter Notebook_ que entregarán. \n",
    "* Formato de entrega: envı́o de link del repositorio en _Github_ ( en caso de ser repositorio privado, invitar como colaborador al usuario de github \"Aerlio\") al correo electrónico del ayudante (*<tomas.ochoa.14@sansano.usm.cl>*), en copia al profesor (*<cvalle@inf.utfsm.cl>*). Especificar el siguiente asunto: [INF395/477/577-2020 Tarea1]\n",
    "* Fecha de entrega y presentaciones: 13 de Noviembre. Hora límite de entrega: 23:00. Cualquier _commit_ luego de la hora límite no será evaluado. Se realizará descuento por atrasos en envío del mail. \n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en tres partes:\n",
    "\n",
    "[1.](#primero) Conceptos básicos de redes neuronales  <br>\n",
    "[2.](#segundo) Reconocimiento de lenguaje de señas <br>\n",
    "[3.](#tercero) Interpretabilidad de CNNs, transfer learning, y skip connections <br>\n",
    "\n",
    "La tarea tiene ejemplos de códigos con los cuales pueden guiarse en gran parte, sin embargo solo son guías y pueden ser creativos al momento de resolver la tarea. Soluciones creativas o elegantes serán valoradas. También en algunas ocaciones se hacen elecciones arbitrarias, ustedes pueden realizar otras elecciones con tal de que haya una pequeña justificación de por qué su elección es mejor o equivalente.\n",
    "Recuerden intercalar su código con comentarios y con celdas _Markdown_ con los comentarios de la pregunta y con cualquier analisis, fórmula o explicación que les parezca relevante para justificar sus procedimientos. \n",
    "Noten que en general cuando se les pide elegir algo o proponer algo no se evaluará mucho la elección en si, en cambio la argumentación detrás de la elección será lo más ponderado.\n",
    "\n",
    "**Es ÁLTAMENTE recomendado realizar esta tarea en _Colab_ de Google (https://colab.research.google.com/notebooks/intro.ipynb#recent=true), con el fin de no depender del rendimiento de su computador personal al momento de entrenar redes neuronales y poder compartir de forma fácil sus avances con su compañer@ de trabajo.** Si bien conlleva sus pros y contras utilizar _Colab_ , existirá una curva de aprendizaje personal que lo ayudará a sacar el mayor provecho a esta herramienta, por ejemplo aprendiendo a guardar los avances realizados, evitando tener que ejecutar todo el código cada vez que se abra _Colab_ . *Tip: Una vez abierto un notebook en _Colab_ ir a **entorno de ejecución**->**Cambiar tipo de entorno de ejecución**, y seleccionár TPU como acelerador por hardware para redes feedforward y GPU para redes convolucionales.*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwJAApzbF4Of"
   },
   "source": [
    "# 1. Conceptos básicos de redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EBy2fWNGmCG"
   },
   "source": [
    "De las redes neuronales artificiales más simples se encuentran las redes densas o _Feed Forward_, donde todas las neuronas de una capa están conectadas a todas las salidas de la capa anterior y envían su señal de activación a todas las neuronas de la siguiente capa. Estas redes, si bien son las más simples, suelen tener desempeños bastante buenos, y en muchas aplicaciones reales son utilizadas, ya sea por si solas o en combinación con otros modelos. Además, son las redes donde más fácil se pueden observar muchos de los fenómenos que se han descubierto a lo largo de los años de desarrollo de esta área del conocimiento, tanto por ser de las redes vigentes más antiguas y por su estructura relativamente simple. En esta primera parte de la tarea exploraremos las redes densas y algunos de sus hiperparámetros más relevantes como la profundidad, el número de unidades, learning rate, etc...; estudiaremos también algunos métodos de regularización y evidenciaremos el problema del _vanishing gradient y el _exploding gradient_, viendo también algunos optimizadores existentes.\n",
    "\n",
    "\n",
    "<h1 align='center'> <img src=\"https://images.fineartamerica.com/images/artworkimages/mediumlarge/1/water-flea-daphnia-magna-ted-kinsman.jpg\" width=\"40%\" height=\"30%\" /> </h1>\n",
    "\n",
    "Para realizar esto usaremos un problema de regresión sencillo y utilizaremos los paquetes tensorflow y keras para explorar los conceptos básicos del mundo de las redes neuronales artificiales. Dado que puede tomar tiempo entrenar redes neuronales, y existe una amplia gama de conceptos a cubrir, utilizaremos un dataset de tamaño limitado con menos de 1000 observaciones, recordar que las redes neuronales tienen una naturaleza _data hungry_ por lo que su desempeño se puede ver limitado por la poca cantidad de observaciones en algunos casos. El dataset en cuestión consiste de 8 atributos (descriptores moleculares) de 546 productos químicos usados para predecir la toxicidad acuática aguda hacia la especie Daphnia Magna, para su descarga y descripción más detallada: https://archive.ics.uci.edu/ml/datasets/QSAR+aquatic+toxicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TadtgytHIXFp"
   },
   "source": [
    "## 1.a Carga de datos y preprocesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nujeesYmts-a"
   },
   "source": [
    "##### I) Partiremos cargando los datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cRBEyJOar8M_"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1c11b62e5dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#from google.colab import files   #-> For Google Colab, there are other methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mheader_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"TPSA\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"SAacc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"H-050\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"MLOPG\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"RDCHI\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"GATS1p\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"nN\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"C-050\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"LC50-response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'qsar_aquatic_toxicity.csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import files   #-> For Google Colab, there are other methods\n",
    "import io\n",
    "uploaded = files.upload()\n",
    "header_list = [\"TPSA\",\"SAacc\",\"H-050\",\"MLOPG\",\"RDCHI\",\"GATS1p\",\"nN\",\"C-050\",\"LC50-response\"]\n",
    "df2 = pd.read_csv(io.BytesIO(uploaded['qsar_aquatic_toxicity.csv']),names=header_list,sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaAufyUjuR0B"
   },
   "source": [
    "##### II) **Comente y visualice** las distribuciones de cada atributo del dataset utilizando herramientas estadísticas básicas, boxplots e histogramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsfyMd3QwUAs"
   },
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKEb3lQpuKiY"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize']=[16,3] # <- Controla el tamaño del plot dentro del Notebook\n",
    "import seaborn as sns  # <- Herramienta complementaria para distintos tipos de plots\n",
    "cols=sns.color_palette(\"cubehelix\", 9) # <-Paleta de colores a utilizar 9 es el número de colores que componen la paleta\n",
    "plt.suptitle('Boxplot de cada característica',size=20,y=1.2)\n",
    "k,K=1,1\n",
    "for i in df2.columns[:]:\n",
    "  if K<=5: plt.subplot(1,5,k)\n",
    "  else: plt.subplot(1,4,k)\n",
    "  plt.title('Atributo: '+str(i))\n",
    "  sns.boxplot(df2[i],color=cols[K-1])\n",
    "  plt.tight_layout()\n",
    "  plt.grid()\n",
    "  if k==5:\n",
    "      k=1\n",
    "      K+=1\n",
    "      plt.show()\n",
    "  else:\n",
    "      k+=1\n",
    "      K+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eldhQ0os0AkJ"
   },
   "outputs": [],
   "source": [
    "plt.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjFz9ORQyyW7"
   },
   "source": [
    "##### III) **Separe** el dataset en conjuntos de entrenamiento, validación y test, para luego estandarizar, considere un 70% de los datos para entrenamiento, un 20% para validación y un 10% para test. Para esto puede utilizar la librería sklearn, en particular las funciones StandarScaler y train_test_split. **Verifique** que el tamaño de los conjuntos se asemeje al indicado. \n",
    "\n",
    "**Pregunta:** ¿Cuál es la función de cada uno de estos conjuntos?\n",
    "\n",
    "Para aclarar conceptos acerca de estos conjuntos: https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMTTF7372zjs"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x=df2.drop(columns=['LC50-response'])\n",
    "y=np.asarray(df2['LC50-response']).reshape(-1,1)\n",
    "x_tr, x_test, y_tr, y_test  = train_test_split(x, y, test_size=0.1, shuffle=True)\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_tr, y_tr, test_size=0.2/0.9, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_M1RvC0p3jrx"
   },
   "outputs": [],
   "source": [
    "scaler_x = StandardScaler()\n",
    "scaler_x.fit(x_tr)\n",
    "x_tr = scaler_x.transform(x_tr)\n",
    "x_val = scaler_x.transform(x_val)\n",
    "x_test = scaler_x.transform(x_test)\n",
    "scaler_y = StandardScaler()\n",
    "scaler_y.fit(y_tr.reshape(-1,1))\n",
    "y_tr = scaler_y.transform(y_tr)\n",
    "y_val = scaler_y.transform(y_val)\n",
    "y_test = scaler_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NV17tmu3slZ"
   },
   "source": [
    "##### IV) **Visualice** de la forma que estime conveniente para realizar comparaciones, las distribuciones para todas las variables (atributos y target) antes de estandarizar, y después de estandarizar para los conjuntos de entrenamiento, validación y test. **Comente**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFe71DFr47tn"
   },
   "outputs": [],
   "source": [
    "for j in [7]: # <- completar\n",
    "  vars=[np.asarray(x)[:,j],x_tr[:,j],x_val[:,j],x_test[:,j]]\n",
    "  for k in range(4):\n",
    "    plt.subplot(1,4,k+1)\n",
    "    plt.title(\"pre,tr,val,tst,variable\") # <- completar\n",
    "    sns.boxplot(vars[k],color=cols[k]) # <- completar puede usar boxplot, histogramas u otra herramienta\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXzIveIQ7oRN"
   },
   "source": [
    "##### V) **Pregunta:** ¿Por qué seleccionar los conjuntos de entrenamiento, validación y test _by hand_ es una mala práctica? ¿Qué beneficios _tramposos_ se pueden obtener de esta mala práctica?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPkX81nkBM1x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mos2m3slLk9g"
   },
   "source": [
    "##### VI) **Bonus:** Tome decisiones, p.ej realice transformaciones, manipulaciones, etc... de manera fundamentada que ayuden a mejorar la conformación de los conjuntos para el posterior entrenamiento de la red neuronal. Evite malas prácticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWiGZA-XL1wD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1STbqEMqk30"
   },
   "source": [
    "## 1.b Primera arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pR8ckP4kIj6o"
   },
   "source": [
    "Partiremos cargando los paquetes necesarios. Conozcamos tensorflow y keras:\n",
    "\n",
    "_TensorFlow_ es una librería de computación matemática, que ejecuta de forma rápida y eficiente gráficos de flujo. Un gráfico de flujo está formado por operaciones matemáticas representadas sobre nudos, y cuya entrada y salida es un vector multidimensional (o tensor) de datos. \n",
    "\n",
    "_Keras_ es una abstracción, un API High-level, para la creación de modelos de aprendizaje. Aporta una sintaxis homogénea y un interface sencillo, modular y ampliable para la creación de redes neurales.\n",
    "\n",
    "Las redes neurales son un tipo particular de gráfico de flujo de datos. Por tanto, TensorFlow y Keras combinan perfectamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cN57CbDFBRjt"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import activations\n",
    "from tensorflow.python.keras.engine import input_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEOW-pWJ9wZm"
   },
   "source": [
    "##### I) Entrene la siguiente red neuronal de una capa con funciónes de activación sigmoidales, función de pérdida MSE, optimizador SGD, y learning rate=0.01 por 500 epochs. Este entrenamiento toma menos de 20 segundos en _Colab_ con entorno de ejecución TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rxqJW02nQR4"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import History \n",
    "\n",
    "# Define architecture\n",
    "input_dense= input_layer.Input(shape=(x_tr.shape[1]))\n",
    "dense=layers.Dense(50, activation='sigmoid',use_bias=True)(input_dense)\n",
    "output_dense=layers.Dense(1, activation='sigmoid',use_bias=True)(dense)\n",
    "model=models.Model(inputs=input_dense, outputs=output_dense)\n",
    "# Compile model\n",
    "model.compile(optimizer=SGD(learning_rate=0.01),loss='mean_squared_error')\n",
    "# Define callbacks (No modificar patience!!!!!!!!! es solo para que la conozcan por el momento)\n",
    "my_callbacks = [History(), # Returns validation and training loss\n",
    "    tf.keras.callbacks.EarlyStopping(patience=500,monitor=\"val_loss\", #Stops training when the validation loss doesnt get better in n°patience consecutive epochs\n",
    "                                     restore_best_weights=True)] \n",
    "\n",
    "# Train model\n",
    "hist_1_b_i = model.fit(x_tr, y_tr, epochs=500, verbose=0, validation_data=(x_val, y_val),callbacks=my_callbacks) \n",
    "#verbose=1 shows epoch per epoch evolution, not necessary if you are planning to plot hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Je-Pu8JNCVNv"
   },
   "source": [
    "Note cómo se puede evaluar todo el conjunto de test en sólo un paso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BJb6hkuCbCR"
   },
   "outputs": [],
   "source": [
    "y_pred=model(x_test) # model.predict(x_test) returns numpy array\n",
    "test_batch_loss=tf.keras.losses.MSE(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkvjVKDXC-uZ"
   },
   "source": [
    "Note cómo se obtiene el error MSE para cada observación en el conjunto de test. Se introdujo a propósito la notación batch para definir la variable python, esta dimensión debe ser siempre la primera dimensión del tensor cuando entrenamos redes neuronales. Un batch es un conjunto de observaciones, dado que estamos tratando con la evaluación del conjunto de test se utilizó un batch de tamaño máximo (igual a la cantidad de observaciones del conjunto de test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2o058TeAC0wz"
   },
   "outputs": [],
   "source": [
    "test_batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgJnEaflDKFr"
   },
   "source": [
    "Obtenga el error MSE promedio para todo el conjunto de test. **Aprecie** cómo se graficará el proceso de entrenamiento de la red neuronal, tendrá que repetir este proceso para reportar resultados múltiples veces durante el ramo. Utilizar verbose=1 para reportar resultados **NO ES VÁLIDO**, dado que es de difícil lectura y ocupa una cantidad de espacio innecesaria, se recomienda utilizar esta opción para estimar cuánto tiempo se demorará en entrenar la red viendo un par de epochs, luego se puede pausar el entrenamiento y desactivar el verbose para volver a entrenar. Esto no es obligatiorio y condicional de cuánto epochs se están entrenando, sin embargo considere que un entrenamiento por 1000 epochs puede ocupar el equivalente a 10 páginas pdfs, lo que dificultará la navegación por el archivo, pues no siempre es posible plegar el output de una celda (depende de cómo se está visualizando el archivo, p.ej al ver un notebook por github no se podrán plegar los outputs). **Comente** el gráfico generado, **Preguntas:** ¿existe overfitting? **¿Qué conclusiones puede sacar al observar el error del conjunto de test y compararlo respecto al conjunto de entrenamiento y validación?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Oy_Sibl_Epe"
   },
   "outputs": [],
   "source": [
    "test_loss_1_b_i=tf.math.reduce_mean(test_batch_loss).numpy() # .numpy() converts tensor to array, tf.convert_to_tensor converts array to tensor\n",
    "plt.title(\"MSE error v/s epochs\")\n",
    "plt.plot(hist_1_b_i.history[\"loss\"],\"b.\",label=\"Train_loss\")\n",
    "plt.plot(hist_1_b_i.history[\"val_loss\"],\"g.\",label=\"Val_loss\")\n",
    "plt.axhline(y=test_loss_1_b_i,color=\"k\",linestyle=\"-.\",label=\"Tst_loss\")\n",
    "plt.xlabel(\"Epochs\"),plt.ylabel(\"MSE Error\")\n",
    "plt.legend(),plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWq9JOzyLzg6"
   },
   "source": [
    "Para evitar reentrenar redes al reconectarse, la red neuronal entrenada se puede guardar (arquitectura, pesos, y configuración de entrenamiento) del siguiente modo: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFWVXY9YD3vv"
   },
   "source": [
    "---> Para verificar que estamos guardando el modelo correctamente: Iniciaremos clonando el modelo, esta función copia la arquitectura del modelo pero no mantiene los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sfFIN-6DRuF"
   },
   "outputs": [],
   "source": [
    "model_clone=tf.keras.models.clone_model(model)\n",
    "[np.all(model_clone.get_weights()[i]==model.get_weights()[i]) for i in range(len(model.get_weights()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_mKdYnGEWEm"
   },
   "source": [
    "----> Para esto setearemos los pesos del modelo clonado igual a los pesos del modelo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "844BnU-ODSqm"
   },
   "outputs": [],
   "source": [
    "model_clone.set_weights(model.get_weights())\n",
    "[np.all(model_clone.get_weights()[i]==model.get_weights()[i]) for i in range(len(model.get_weights()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JLmwGDQE5DC"
   },
   "source": [
    "---> Procederemos a guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yef3XyyBZmS"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zK4GjFHLKPF"
   },
   "outputs": [],
   "source": [
    "model.save('saved_model/1_b_i')  #<- guardar modelo con pesos incluidos, cuidado con sobre escribir sobre modelos ya guardados\n",
    "# esta función está por deprecarse, aún así de momento está funcionando\n",
    "# existe la siguiente alternativa: 1) guardar los pesos del modelo model.save_weights(\"filepath\"), \n",
    "# 2) luego al querer cargar el modelo se debe definir la arquitectura del modelo (la misma, e.d correr solo #define architecture en 1.b.i)  \n",
    "# 3) usar model.set_weights(model.load_weights(\"filepath\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Mn-T_JeIJHG"
   },
   "source": [
    "---> Verificamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mnEPOThjMf66"
   },
   "outputs": [],
   "source": [
    "\n",
    "model_new=tf.keras.models.load_model('saved_model/1_b_i/') #<- cargar modelo\n",
    "[np.all(model_clone.get_weights()[i]==model_new.get_weights()[i]) for i in range(len(model_new.get_weights()))] # <- verificar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grSCWxmRKi87"
   },
   "source": [
    "##### II) **Entrene** una red neuronal con los mismos hiperparámetros que en la sección anterior pero con función de activación ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzmyRffZKWDw"
   },
   "outputs": [],
   "source": [
    "input_dense= input_layer.Input(shape=(x_tr.shape[1]))\n",
    "#...\n",
    "hist_1_b_ii = model.fit(x_tr, y_tr, epochs=500, verbose=0, validation_data=(x_val, y_val),callbacks=my_callbacks) \n",
    "test_loss_1_b_ii=tf.math.reduce_mean(tf.keras.losses.MSE(y_test, model(x_test))).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSuDKKBUbi86"
   },
   "source": [
    "##### III) **Cree** una función que grafique los resultados, puede basarse en el siguiente código. La función creada la puede ir modificando en los siguientes items para reducir esfuerzos (fijarse en que la visualización sea lo más clara posible). **Visualice y compare** los resultados con los obtenidos en el punto 1.b.I). **Comente**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJZQGYP8Bmy3"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"]=[16,3]\n",
    "hists=[hist_1_b_i.history,hist_1_b_ii.history]\n",
    "tsts=[test_loss_1_b_i,test_loss_1_b_ii]\n",
    "titles=[\"MSE error v/s epochs [Sigmoidal]\",\"MSE error v/s epochs [ReLU]\"]\n",
    "def graph_results(hists,tsts,titles):\n",
    "  fig, axes = plt.subplots(1, len(hists), sharey=True) # sharey to keep the same y lims for all subplots. \n",
    "                                            # En algunos casos esto puede jugar en contra para una buena visualización -> ver siguiente comentario\n",
    "  for i,ax in enumerate(axes):\n",
    "    ax.set_title(titles[i])\n",
    "    ax.plot(hists[i][\"loss\"],\"b.\",label=\"Train_loss\")\n",
    "    ax.plot(hists[i][\"val_loss\"],\"g.\",label=\"Val_loss\")\n",
    "    ax.axhline(y=tsts[i],color=\"k\",linestyle=\"-.\",label=\"Tst_loss\")\n",
    "    ax.set_xlabel(\"Epochs\"),ax.set_ylabel(\"MSE Error\")\n",
    "    # ax.set_ylim([ym,YM])  # <- Puede convenir insertar como entrada a la función límite inferiores y superiores para ajuste manual\n",
    "    if i==len(axes)-1: ax.legend()\n",
    "    ax.grid()\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "graph_results(hists,tsts,titles) # llamado simple para graficar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KCphAFxPhNd"
   },
   "source": [
    "## 1.c Sensibilidad a hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYfg0BM6WOyA"
   },
   "source": [
    "##### I) **Utilice** la siguiente función (o implemente una propia) para **recopilar** el error de entrenamiento, validación y test **según** el número de capas en la red neuronal y el número de neuronas. Considere el mismo número de neuronas para cada capa. Seleccione dos valores para la cantidad de neuronas entre 10 y 100, y varíe la profundidad entre 1 y 3, e.d 6 redes en total. Utilice la f° de activación ReLU, 500 epochs, lr=0.01, y error MSE. **Encuentre los hiperparámetros (n° neuronas y profundidad) que obtienen el menor error de validación**. \n",
    "\n",
    "**Pregunta:** ¿Por qué el menor error de validación y no de test?\n",
    "\n",
    "**Visualice** y **Comente** los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zThZQQrPWxd"
   },
   "outputs": [],
   "source": [
    "def train_network_1_c_i(prof_dense,n_neurons):\n",
    "  input_dense=input_layer.Input(shape=(x_tr.shape[1]))\n",
    "  for i in range(prof_dense):\n",
    "    if i==0:\n",
    "      dense=layers.Dense(n_neurons, activation='relu',use_bias=True)(input_dense)\n",
    "    else:\n",
    "      dense=layers.Dense(n_neurons, activation='relu',use_bias=True)(dense)\n",
    "  output_dense=layers.Dense(1, activation='relu',use_bias=True)(dense)\n",
    "  model=models.Model(inputs=input_dense, outputs=output_dense)\n",
    "  # Compile model\n",
    "  model.compile(optimizer=SGD(learning_rate=0.001),loss='mean_squared_error')\n",
    "  # define callbacks (keep patience at 100)\n",
    "  my_callbacks = [History(), # Returns validation and training loss\n",
    "    tf.keras.callbacks.EarlyStopping(patience=100,monitor=\"val_loss\", #Stops training when the validation loss doesnt get better in n°patience consecutive epochs\n",
    "                                     restore_best_weights=True)] # Returns best validation loss\n",
    "  # Train model\n",
    "  hist = model.fit(x_tr, y_tr, epochs=500, verbose=0, validation_data=(x_val, y_val),callbacks=my_callbacks)\n",
    "  test_loss=tf.math.reduce_mean(tf.keras.losses.MSE(y_test, model(x_test))).numpy()\n",
    "  return(hist,test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrhOoVJPcKeV"
   },
   "outputs": [],
   "source": [
    "h1,t1=train_network_1_c_i(3,100)\n",
    "min_val_loss_1=np.min(h1.history[\"val_loss\"])\n",
    "graph_results([h1.history,h1.history],[t1,t1],[\"asd\",\"qwe\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6e7ocuQcVIu"
   },
   "source": [
    "##### II) **Realice** un experimento similar, ahora variando el learning rate entre [-1e-6 y 1e-1], entrene 6 redes neuronales con distintos learning rate. Para esto **implemente una función** semejante a la utilizada en el punto anterior, use la arquitectura e hiperparámetros dados. **Encuentre el learning rate que obtiene el menor error de validación. Visualizar y comentar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uU2iM9crhfdU"
   },
   "outputs": [],
   "source": [
    "input_dense= input_layer.Input(shape=(x_tr.shape[1]))\n",
    "dense=layers.Dense(50, activation='relu',use_bias=True)(input_dense)\n",
    "dense=layers.Dense(50, activation='relu',use_bias=True)(dense)\n",
    "output_dense=layers.Dense(1, activation='relu',use_bias=True)(dense)\n",
    "model=models.Model(inputs=input_dense, outputs=output_dense)\n",
    "model.compile(optimizer=SGD(learning_rate=?),loss='mean_squared_error')\n",
    "my_callbacks = [History(), # Returns validation and training loss\n",
    "    tf.keras.callbacks.EarlyStopping(patience=200,monitor=\"val_loss\", # Mantener patience en 200\n",
    "                                     restore_best_weights=True)]\n",
    "hist = model.fit(x_tr, y_tr, epochs=500, verbose=0, validation_data=(x_val, y_val),callbacks=my_callbacks)\n",
    "test_loss=tf.math.reduce_mean(tf.keras.losses.MSE(y_test, model(x_test))).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UlgVEvGhUNF"
   },
   "source": [
    "##### III) **Realice** un experimento similar, ahora variando el learning decay, entrene 6 redes neuronales para distintos decay. Para esto **implemente una función** semejante a la utilizada en el punto anterior. **Encuentre el learning decay que obtiene el menor error de validación. Visualizar y comentar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EesLb2SWczHy"
   },
   "outputs": [],
   "source": [
    "lear_decay = np.logspace(-6,0,6)\n",
    "lear_decay=np.around(lear_decay,decimals=6)\n",
    "\n",
    "input_dense= input_layer.Input(shape=(x_tr.shape[1]))\n",
    "dense=layers.Dense(50, activation='relu',use_bias=True)(input_dense)\n",
    "dense=layers.Dense(50, activation='relu',use_bias=True)(dense)\n",
    "output_dense=layers.Dense(1, activation='relu',use_bias=True)(dense)\n",
    "model=models.Model(inputs=input_dense, outputs=output_dense)\n",
    "model.compile(optimizer=SGD(learning_rate=0.01,decay=?),loss='mean_squared_error')\n",
    "\n",
    "my_callbacks = [History(), # Returns validation and training loss\n",
    "    tf.keras.callbacks.EarlyStopping(patience=200,monitor=\"val_loss\", # Mantener patience en 200\n",
    "                                     restore_best_weights=True)]\n",
    "hist = model.fit(x_tr, y_tr, epochs=500, verbose=0, validation_data=(x_val, y_val),callbacks=my_callbacks)\n",
    "test_loss=tf.math.reduce_mean(tf.keras.losses.MSE(y_test, model(x_test))).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsR3ovRkczFy"
   },
   "source": [
    "##### IV) **Realice** un experimento similar, ahora variando el optimizador para la arquitectura e hiperparámetros dados, pruebe con los optimizadores [SGD, Adagrad, Adadelta, Adam y RMSprop]. Para esto **implemente una función** semejante a la utilizada en el punto anterior. **Pregunta:** ¿En qué optimizadores no tiene sentido utilizar el learning decay, por qué? **Visualizar y comentar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3M2ByhNDdiC_"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta\n",
    "\n",
    "input_dense= input_layer.Input(shape=(x_tr.shape[1]))\n",
    "dense=layers.Dense(50, activation='relu',use_bias=True)(input_dense)\n",
    "dense=layers.Dense(50, activation='relu',use_bias=True)(dense)\n",
    "output_dense=layers.Dense(1, activation='relu',use_bias=True)(dense)\n",
    "model=models.Model(inputs=input_dense, outputs=output_dense)\n",
    "model.compile(optimizer=?(learning_rate=0.001),loss='mean_squared_error')\n",
    "# Define callbacks\n",
    "my_callbacks = [History(), \n",
    "    tf.keras.callbacks.EarlyStopping(patience=500,monitor=\"val_loss\", # (No modificar patience!!!!!!!!!)\n",
    "                                     restore_best_weights=True)]\n",
    "hist = model.fit(x_tr, y_tr, epochs=500, verbose=0, validation_data=(x_val, y_val),callbacks=my_callbacks)\n",
    "test_loss=tf.math.reduce_mean(tf.keras.losses.MSE(y_test, model(x_test))).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkKthB-agUTC"
   },
   "source": [
    "##### V) **Realice** un expermiento similar, ahora variando el batch_size entre 1 y x_tr.shape[0] incluyendo los extremos. Entrene 6 redes neuronales con la arquitectura e hiperparámetros dados. Para esto **implemente una función** semejante a la utilizada en el punto anterior. Para un batch_size=1 el entrenamiento se va a demorar más que en puntos anteriores, aprox. 1 segundo en _Colab_. **Visualizar y comentar**. **Preguntas:** ¿A qué es equivalente entrenar con un batch_size = 1 y batch_size=x_tr.shape[0]? ¿Cuál es el batch_size por default?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmxaOVIMd3Uh"
   },
   "outputs": [],
   "source": [
    "n_batches=6\n",
    "batches=np.round(np.linspace(1,x_tr.shape[0],n_batches))\n",
    "\n",
    "input_dense= input_layer.Input(shape=(x_tr.shape[1]))\n",
    "dense=layers.Dense(50, activation='relu',use_bias=True)(input_dense)\n",
    "dense=layers.Dense(50, activation='relu',use_bias=True)(dense)\n",
    "output_dense=layers.Dense(1, activation='relu',use_bias=True)(dense)\n",
    "model=models.Model(inputs=input_dense, outputs=output_dense)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),loss='mean_squared_error')\n",
    "# Define callbacks\n",
    "my_callbacks = [History(), \n",
    "    tf.keras.callbacks.EarlyStopping(patience=100,monitor=\"val_loss\", # (No modificar patience!!!!!!!!!)\n",
    "                                     restore_best_weights=True)]\n",
    "hist = model.fit(x_tr, y_tr, epochs=500, verbose=0, batch_size=?,validation_data=(x_val, y_val),callbacks=my_callbacks)\n",
    "test_loss=tf.math.reduce_mean(tf.keras.losses.MSE(y_test, model(x_test))).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ifxv2J_YlckE"
   },
   "source": [
    "## 1.d Inicializaciones, pesos y gradientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xz6XVoll9hr"
   },
   "source": [
    "##### I) Utilizando las siguientes arquitecturas proceda a graficar la distribución de pesos de las distintas capas bajo inicialización uniforme (incluyendo bias). Adicionalmente calcule el gradiente de la función de pérdida (loss) para el conjunto de entrenamiento (promedio del gradiente del error de todos los datos de entrenamiento) respecto a los pesos en las distintas capas. **Visualize, compare y comente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gix3Xod3nTqM"
   },
   "outputs": [],
   "source": [
    "# Define architecture (1)\n",
    "input_dense= input_layer.Input(shape=(8))\n",
    "dense=layers.Dense(100, activation='tanh',use_bias=True, kernel_initializer=\"uniform\")(input_dense)\n",
    "dense=layers.Dense(100, activation='tanh',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "dense=layers.Dense(100, activation='tanh',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "dense=layers.Dense(100, activation='tanh',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "output_dense=layers.Dense(1, activation='tanh',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "model=models.Model(inputs=input_dense, outputs=output_dense)\n",
    "\n",
    "# Define architecture (2)\n",
    "input_dense= input_layer.Input(shape=(8))\n",
    "dense=layers.Dense(100, activation='relu',use_bias=True, kernel_initializer=\"uniform\")(input_dense)\n",
    "dense=layers.Dense(100, activation='relu',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "dense=layers.Dense(100, activation='relu',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "dense=layers.Dense(100, activation='relu',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "output_dense=layers.Dense(1, activation='relu',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "model=models.Model(inputs=input_dense, outputs=output_dense)\n",
    "\n",
    "# Get weights\n",
    "weights=model.get_weights()\n",
    "# Get gradient\n",
    "with tf.GradientTape() as tape:\n",
    "  y_pred= model(x_tr)\n",
    "  loss = tf.reduce_mean(tf.square(y_pred-y_tr)) #MSE loss\n",
    "  grad=tape.gradient(loss,model.trainable_weights) \n",
    "# gradient only calculated, if u want to apply it to update weights the model must have an optimizer, for example set model.optimizer=tf.keras.optimizers.Adam(lr) \n",
    "# and then use: model.optimizer.apply_gradients(zip(grad, model.trainable_variables)) to update weights. Equivalent to an epoch of maximum batch size (all training set) in this code\n",
    "# model.compile and model.fit does this, with extra implementations, like variable batch size,\n",
    "# so it's not necessary to do it manually in this case. If u pay attention to the code all the flow of information is in the form\n",
    "# of tensors. This setup can be necessary in the case that u want to implement a custom loss that use exogenous variables to compute the loss, other than only y_pred and y_true\n",
    "# for the best of my knowledge u can define a custom loss to use in model.compile and model.fit, but only if u are using this two variables (y_true,y_pred),\n",
    "# exogenous variables are not supported\n",
    "\n",
    "# As example, if u want to define a mean quintic error loss, only using y_pred and y_true and want to keep all the cool functionalities, as callbacks, from model.compile\n",
    "# and model.fit:\n",
    "# def custom_loss(y_true,y_pred):\n",
    "#   return(tf.reduce_mean(tf.math.pow(y_true-y_pred,5)))\n",
    "# model.compile (optimizer='rmsprop',loss=\"custom_loss\")\n",
    "# model.fit(x_tr, y_tr, epochs=500, verbose=0, batch_size=?,validation_data=(x_val, y_val),callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0J-KnoPrlKA"
   },
   "outputs": [],
   "source": [
    "# To understand where are the weights and number of weights:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOkdYfdWos2A"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"]=[16,3]\n",
    "plt.subplot(1,4,1)\n",
    "plt.hist( ? ,bins= ?,label=[\"layer o bias?:1,2,3,4,5?\",\"layer o bias?:1,2,3,4,5?\",\"layer o bias?:1,2,3,4,5?\",\"layer o bias?:1,2,3,4,5?\",\"layer o bias?:1,2,3,4,5?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCkTKON9sCg8"
   },
   "source": [
    "##### II) Repita el experimento para las inicializaciones de kernel HE_uniform, Glorot normal y Glorot uniform. **Visualice, comente, y compare** \n",
    "\n",
    "**Pregunta** ¿Es posible inicializar los bias? ¿Cómo sería el código?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6p8dTQxsyt1"
   },
   "outputs": [],
   "source": [
    "kernel_initializer=['he_uniform','glorot_normal','glorot_uniform'][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0VS50u2uEFe"
   },
   "source": [
    "##### III) Utilizando las arquitecturas siguientes. **Recolecte** los pesos y gradientes al inicializar, **entrene** la red neuronal, y **recolecte** nuevamente los pesos y gradientes, junto a los errores de entrenamiento, validación y test. (En la medida de lo posible!). **Visualice, compare y comente**. Ciertos conceptos ya debiesen salir a colación para explicar lo que está sucediendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0xNvUXpu0Ic"
   },
   "outputs": [],
   "source": [
    "# 1st arch\n",
    "input_dense= input_layer.Input(shape=(8))\n",
    "dense=layers.Dense(100, activation='sigmoid',use_bias=True, kernel_initializer=\"uniform\")(input_dense)\n",
    "dense=layers.Dense(100, activation='sigmoid',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "dense=layers.Dense(100, activation='sigmoid',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "dense=layers.Dense(100, activation='sigmoid',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "dense=layers.Dense(100, activation='sigmoid',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "dense=layers.Dense(100, activation='sigmoid',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "dense=layers.Dense(100, activation='sigmoid',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "output_dense=layers.Dense(1, activation='linear',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "model=models.Model(inputs=input_dense, outputs=output_dense)\n",
    "\n",
    "# 2nd arch\n",
    "input_dense= input_layer.Input(shape=(8))\n",
    "dense=layers.Dense(1000, activation='sigmoid',use_bias=False, kernel_initializer=\"he_uniform\")(input_dense)\n",
    "output_dense=layers.Dense(1, activation='linear',use_bias=False, kernel_initializer=\"uniform\")(dense)\n",
    "model=models.Model(inputs=input_dense, outputs=output_dense)\n",
    "\n",
    "# Get initial weights\n",
    "weights_ini=model.get_weights()\n",
    "# Get initial gradient\n",
    "with tf.GradientTape() as tape:\n",
    "  #...\n",
    "# Compile model\n",
    "model.compile(optimizer=SGD(learning_rate=0.01),loss='mean_squared_error')\n",
    "# Train model\n",
    "hist = model.fit(x_tr, y_tr, epochs=200, verbose=0, validation_data=(x_val, y_val),callbacks=[History()]) #only history as callback\n",
    "  \n",
    "# Get final weights\n",
    "weights_fin=model.get_weights()\n",
    "# Get final gradient\n",
    "with tf.GradientTape() as tape:\n",
    "  #..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSDE057Xyvm_"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CoEfSUuwxyiI"
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.hist(grad_ini)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(grad_fin)\n",
    "plt.show() #and weights!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xJZDPImxMLd"
   },
   "source": [
    "## 1.d Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Et6CI4U0ywC"
   },
   "source": [
    "##### i) Utilizando la siguiente arquitectura experimente con regularización l1 y l2 usando distintos valores de $\\lambda$ para las distintas capas, pero manteniendo el mismo tipo de regularización en ambas capas (l1 ó l2). **Entrene** 4 redes neuronales para cada norma con distintos valores de $\\lambda$ en cada capa (8 redes en total). Utilice las variaciones de $\\lambda$ que desee, puede usar las indicadas si desea. **Visualice y comente** los errores de entrenamiento, validación **y la resta de ambos errores** (e.d error_tr-error_val). \n",
    "\n",
    "**Pregunta:** ¿Cómo se comportarán los pesos de la red neuronal para la norma l1 y para la norma l2 en función de $\\lambda$? **Apoyarse en visualización de los pesos al final del entrenamiento para responder la pregunta.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GZUAYX632eV"
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l1,l2\n",
    "# Variaciones de lambda: \n",
    "# En las dos capas y para cada norma probar las 4 combinaciones:\n",
    "lambda_1st=[0,0.1]\n",
    "lambda_2nd=[0,0.1]\n",
    "\n",
    "# Define architecture\n",
    "input_dense= input_layer.Input(shape=(8))\n",
    "dense=layers.Dense(500, activation='relu',activity_regularizer=l2(lambda_1st[1]),use_bias=True, kernel_initializer=\"glorot_normal\")(input_dense)\n",
    "dense=layers.Dense(500, activation='relu',activity_regularizer=l2(lambda_2nd[1]),use_bias=True, kernel_initializer=\"glorot_normal\")(input_dense)\n",
    "output_dense=layers.Dense(1, activation='relu',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "model=models.Model(inputs=input_dense, outputs=output_dense)\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),loss='mean_squared_error')\n",
    "# Train model\n",
    "hist = model.fit(x_tr, y_tr, epochs=200, verbose=0, validation_data=(x_val, y_val),callbacks=[History()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqTLRG2oBKBL"
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist.history[\"loss\"],\"r\")\n",
    "plt.plot(hist.history[\"val_loss\"],\"b\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.asarray(hist.history[\"loss\"])-np.asarray(hist.history[\"val_loss\"]),\"g\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apLlcIKl7oE2"
   },
   "source": [
    "##### II) Experimentaremos con el método dropout. Probaremos con distintos valores de Dropout para ambas capas de la arquitectura presentada, de manera similar al punto anterior. Entrene 9 redes neuronales utilizando las combinaciones indicadas. **Visualizar, comparar y comentar** utilizando los errores de entrenamiento, validación y la resta entre ambos valores.\n",
    "\n",
    "**Preguntas:** ¿Qué es/hace dropout? ¿Por qué es considerado un método de regularización?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QI37-i09ijV"
   },
   "outputs": [],
   "source": [
    "dropout_1st_layer=[0,0.3,0.6]\n",
    "dropout_2nd_layer=[0,0.3,0.6]\n",
    "\n",
    "# Define architecture\n",
    "input_dense= input_layer.Input(shape=(8))\n",
    "dense=layers.Dense(500, activation='relu',use_bias=True, kernel_initializer=\"glorot_normal\")(input_dense)\n",
    "dense=layers.Dropout(dropout_1st_layer[1])(dense)\n",
    "dense=layers.Dense(500, activation='relu',use_bias=True, kernel_initializer=\"glorot_normal\")(dense)\n",
    "dense=layers.Dropout(dropout_2nd_layer[2])(dense)\n",
    "output_dense=layers.Dense(1, activation='relu',use_bias=True, kernel_initializer=\"uniform\")(dense)\n",
    "model=models.Model(inputs=input_dense, outputs=output_dense)\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.01),loss='mean_squared_error')\n",
    "# Train model\n",
    "hist = model.fit(x_tr, y_tr, epochs=200, verbose=0, validation_data=(x_val, y_val),callbacks=[History()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOzoJdN8-TsQ"
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist.history[\"loss\"],\"r\")\n",
    "plt.plot(hist.history[\"val_loss\"],\"b\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.asarray(hist.history[\"loss\"])-np.asarray(hist.history[\"val_loss\"]),\"g\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KQgs52MAHEQ"
   },
   "source": [
    "## 1.e Extreme Learning Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-WfVB4y_4di"
   },
   "source": [
    "##### I) Una aproximación para obtener modelos grandes que no sobreajustan es la implementada por ELM. Explique en qué consiste la idea de ELM y por qué esto podría evitar sobreajuste a pesar de utilizar modelos con gran número de parámetros.\n",
    "\n",
    "Entrene una ELM de una capa fija y una capa oculta, la primera con un número relativamente grande. Puede utilizar los valores propuestos en el código u otros que le parezcan convenientes.\n",
    "\n",
    "Comente sobre el número total de parámetros y el número de parametros entrenables con respecto a los modelos anteriores. \n",
    "\n",
    "**Preguntas:** ¿Cómo se desempeña la red? ¿El número elevado de parámetros totales implica necesariamente _overfitting_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIWBzVAFAGin"
   },
   "outputs": [],
   "source": [
    "# Define architecture\n",
    "input_dense= input_layer.Input(shape=(?))\n",
    "dense=layers.Dense(5000, activation='relu',use_bias=True,trainable=False)(input_dense)\n",
    "#............"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCSin76GDGQh"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vKuR4AIi_-4"
   },
   "source": [
    "# 2. Reconocimiento de lenguaje de señas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyOSDqQwjEjO"
   },
   "source": [
    "Una de las áreas donde las redes neuronales han obtenido desempeños decisivamente superiores al resto de los métodos existentes, al menos en su momento, es en el reconocimiento de imágenes. La capacidad de las redes convolucionaes de aprender y extraer patrones sobre patrones hasta obtener características de alto nivel, representativas de atributos de las imágenes, ha permitido desempeños superiores a los obtenidos por otros métodos de aprendizaje automático o inteligencia aritificial, e incluso en algunos casos al desempeño humano.\n",
    "\n",
    "Una de las tareas usuales que se pueden resolver con redes neuronales convolucionales es la clasificación de imágenes. Para este punto nos basaremos en un dataset de lenguaje de señas, su descripción detallada se puede encontrar en https://www.kaggle.com/datamunge/sign-language-mnist (No es necesario descargar directamente el dataset si está usando _Colab_ como es sugerido)\n",
    "\n",
    "<h1 align='center'> <img src=\"https://i1.wp.com/25.media.tumblr.com/tumblr_mdcs1cF4nn1ri2o31o1_1280.png\" width=\"100%\" height=\"30%\" /> </h1>\n",
    "\n",
    "\n",
    "Note que el entrenamiento de redes convolucionales se beneficia particularmente del uso de unidades de procesamiento gráfico, por lo cual podría ser recomendable utilizarlas en caso de disponer, o considerar correr los codigos completos una vez verificado su funcionamiento en una sesión de Collab acelerada por GPU, entre otras opciones de GPU en la nube existentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35xO3qNrk03n"
   },
   "source": [
    "## 2.a Carga de datos y visualizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QlClvRWk5fk"
   },
   "source": [
    "##### I) Iniciaremos cargando los datos. Para esto necesitará crear una cuenta en kaggle, dirigirse a su perfil, ir a Account, y en la sección API apretar _Create new API token_ , se descargará un archivo kaggle.json, ábralo como archivo de texto y obtenga su username y key. Luego ejecute el siguiente código (desconozco por qué pero a veces hay que ejecutar el código 2 veces para que funcione). Solución obtenida desde el hilo: https://gist.github.com/jayspeidell/d10b84b8d3da52df723beacc5b15cb27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sq9RDFh4m5Uk"
   },
   "outputs": [],
   "source": [
    "username=\"\"\n",
    "key=\"\"\n",
    "!pip install -q kaggle\n",
    "api_token = {\"username\":username,\"key\":key}\n",
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = str(username)\n",
    "os.environ['KAGGLE_KEY'] = str(key)\n",
    "!kaggle datasets download -d datamunge/sign-language-mnist\n",
    "if not os.path.exists(\"/content/competitions/data_sign\"):\n",
    "    os.makedirs(\"/content/competitions/data_sign\")\n",
    "os.chdir('/content/competitions/data_sign')\n",
    "for file in os.listdir():\n",
    "    if file[-4:]==\".zip\":\n",
    "      zip_ref = zipfile.ZipFile(file, 'r')\n",
    "      zip_ref.extractall()\n",
    "      zip_ref.close()\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OP0EUOrADwj1"
   },
   "source": [
    "Si en el siguiente código obtiene error de directorio ejecutar de nuevo celda superior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4oyQaxOog7e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_tr=pd.read_csv(\"sign_mnist_train.csv\")\n",
    "X_tmp=df_tr.values[:,1:].reshape(-1,28,28,1)\n",
    "Y_tmp=df_tr.values[:,:1]\n",
    "df_tst=pd.read_csv(\"sign_mnist_test.csv\")\n",
    "X_tst=df_tst.values[:,1:].reshape(-1,28,28,1)\n",
    "Y_tst=df_tst.values[:,:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2m0RVoEVEE-g"
   },
   "source": [
    "Para evitar largos tiempos de entrenamiento y hacer más desafiante el problema, sacrificaremos data de entrenamiento. **Ejectuar el siguiente código**. Mantendremos el tamaño del conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KdsgZHeEF_B"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sf=StratifiedShuffleSplit(n_splits=1, test_size=2000, random_state=0)\n",
    "for smaller_index,data_index in sf.split(X_tmp, Y_tmp): # en realidad este método está pensado para hacer cross-validation con clases balanceadas,\n",
    "                                                                        # ahora lo ocupamos solamente para extraer 1200 observaciones manteniendo la proporción de clases\n",
    "                                                                          # del dataset original\n",
    "    x_tmp=X_tmp[data_index]\n",
    "    y_tmp=Y_tmp[data_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rYaIt_xtGqu"
   },
   "source": [
    "##### II) **Visualice** algunas imágenes de cada una de las catégorias junto con sus nombres. \n",
    "\n",
    "**Preguntas:** ¿Qué pares de categorías cree podrían ocasionar problemas al momento de clasificación? ¿Por qué hay letras omitidas (inferir viendo abecedario de lenguaje de señas americano)? ¿Las categorías están balanceada? ¿Cuántos canales están disponibles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gY4D_xL5ulNd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"]=[16,4]\n",
    "letters=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\"]\n",
    "fig, axs = plt.subplots(1,4)\n",
    "for i,ax in enumerate(axs):\n",
    "  ax.imshow(x_tmp[np.where(y_tmp[:,0]==0)[0][0],:,:,0], cmap = \"gray\") # arreglar error \n",
    "  ax.text(1.5, 2.2, letters[i], bbox={'facecolor': 'white', 'pad': 3},fontsize=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xW6fXGR20Gp6"
   },
   "source": [
    "## 2.b Preprocesamiento\n",
    "\n",
    "Conforme el conjunto en entrenamiento y validacion a partir de x_tmp e y_tmp con proporciones de 80% y 20% respectivamente, preocúpese de que los conjuntos de entrnamiento y validación mantengan la proporción (aprox.) para cada clase (mantener equilibrio de clases), inspírese en el código utilizado para reducir la cantidad de datos (sección 2.a). Transforme la escala de las imágenes, de $[0,255]$ a $[-1,1]$. Utilice la función `get_dummies` de pandas para transformar $y$ a _encodding_ _one hot vector_. \n",
    "\n",
    "**Preguntas:**\n",
    "¿Perdemos información con este preprocesamiento? ¿Qué representa cada uno de los valores de la tupla `x_tr.shape`? \n",
    "\n",
    "¿Podemos considerar los valores de $y$ como valores numéricos o debemos transformarlos de alguna forma? ¿Por qué? \n",
    "\n",
    "¿Cómo se transforma el `.shape` de $y$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsSXBFC50-P4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit # <- suggestion\n",
    "from keras.utils.np_utils import to_categorical\n",
    "x_tr = x_tr/127.5 - 1\n",
    "\n",
    "# . . . \n",
    "y_tr = pd.get_dummies(y_tr[:,0],len(letters)).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnUVfkKw5_6q"
   },
   "source": [
    "## 2.c Primera red Convolucional\n",
    "\n",
    "Entrenaremos una primera red convolucional sobre los datos, con la mayoría de los parámetros por defecto. Cree primero la red siguiendo la estructura $C\\times P\\times C\\times P \\times D$ donde $C$ representa una capa convolucional, $P$ una capa de _Max pooling_ y $D$ una capa densa. Note que antes de la capa densa debe agregar una capa _Flatten_ que transforma los filtros a vectores que luego pueden ser utilizados por la capa densa. \n",
    "\n",
    "Para los parámetros de las capas, fijaremos ambas capas convolucionales con 128 filtros de $3\\times 3$, stride por default, y _padding 'same'_ (es decir agregaremos 0 a los bordes de la imágen de tal manera que se preserve la dimiensión de la imágen al atravesar la capa; y las capas de _pooling_ tendrán tamaño y _stride_ $2\\times 2$, como muestra el código. **Note que a diferencia de la pregunta 1 aprovecharemos al máximo el lenguaje high-level keras.**\n",
    "\n",
    "Utilice el método `.summary` del modelo para ver la cantidad de parámetros y las dimensiones de los outputs de cada capa (note que cómo en la primera capa especificamos el `input_shape` podemos llamar el método antes de compilar el modelo o de pasarle datos. **Justifique** el número parámetros y el _Output Shape_ de cada capa en función de la estructura de la red y lo aprendido en clases. \n",
    "\n",
    "**Preguntas:**\n",
    "\n",
    "¿Por qué la capa de salida debe tener 24 neuronas? ¿Qué operación efectúa la activación _SoftMax_? ¿Qué representaría en terminos del problema el vector de salida de la red?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0eiIkzu6zlD"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Primera capa C x P\n",
    "model.add(Conv2D(filters=128,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=x_tr.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Segunda capa C x P \n",
    "model.add(Conv2D(filters=128,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Capa flatten y D\n",
    "model.add(Flatten())    \n",
    "model.add(Dense(units=24, activation='softmax')) # output\n",
    "\n",
    "    \n",
    "# summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnzVFHK97GoK"
   },
   "source": [
    "## 2.d Primer entrenamiento\n",
    "\n",
    "##### I) Compile la red definida en el item anterior. Para esta pregunta puede usar los optimizadores configurados por defecto, y debe usar como _loss_ _Categorical Crossentropy_.\n",
    "\n",
    "Entrene la red hasta observar convergencia recuperando su `history`. Grafique como varia el _accuracy_ en entrenamiento y validación a lo largo del aprendizaje. Adicionalmente calcule el accuracy para todo el conjunto de test. Mida igualmente el _categorical accuracy_ como se muestra en el código.  \n",
    "\n",
    "**Preguntas:**\n",
    "\n",
    "¿Por qué preferimos medir _crossentropy_ y no por ejemplo _MSE_ en este problema? ¿Qué valor representa el _accuracy_? ¿Le parece buena medida de desempeño para este problema? ¿Por qué luego de lograr un accuracy de 100% en el conj. de entrenamiento siguen actualizándose los pesos de la red? ¿A qué corresponde cada valor de la lista que retorna model.evaluate?\n",
    "\n",
    "**Recordar usar entorno GPU en _Colab_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-67dsaYZ7VqE"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import History, EarlyStopping\n",
    "\n",
    "my_callbacks = [History(), # Returns validation and training loss\n",
    "    EarlyStopping(patience=100,monitor=\"val_loss\", #Stops training when the validation loss doesnt get better in n°patience consecutive epochs,keep it at 100 it's only to show u\n",
    "                                     restore_best_weights=True)]\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "history = model.fit(x_tr, y_tr, epochs=20, validation_data=(x_val,y_val),verbose=0,callbacks=mycallbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wTWsUiKv-nWo"
   },
   "outputs": [],
   "source": [
    "acc_tst = model.evaluate(x_tst, y_tst, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdvUSq6_7ZCB"
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"acc\"],label=\"training accuracy\")\n",
    "#...\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"loss\"],label=\"training loss\")\n",
    "#...\n",
    "plt.axhline(y=acc_tst[0],color=\"k\",linestyle=\"-.\",label=\"test loss\")\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxVj7mTzAdx7"
   },
   "source": [
    "Para evitar reentrenar redes al reconectarse, la red neuronal entrenada se puede guardar (arquitectura, pesos, y configuración de entrenamiento) del siguiente modo: \n",
    "\n",
    "Para mayor información: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#scrollTo=sI1YvCDFzpl3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1OhEjnNAdx8"
   },
   "source": [
    "---> Para verificar que estamos guardando el modelo correctamente: Iniciaremos clonando el modelo, esta función copia la arquitectura del modelo pero no mantiene los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxPJqRpJAdx8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model_clone=tf.keras.models.clone_model(model)\n",
    "[np.all(model_clone.get_weights()[i]==model.get_weights()[i]) for i in range(len(model.get_weights()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfesb0SOAdx-"
   },
   "source": [
    "----> Para esto setearemos los pesos del modelo clonado igual a los pesos del modelo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKDhlZjzAdx_"
   },
   "outputs": [],
   "source": [
    "model_clone.set_weights(model.get_weights())\n",
    "[np.all(model_clone.get_weights()[i]==model.get_weights()[i]) for i in range(len(model.get_weights()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4t_Tp-WAdyB"
   },
   "source": [
    "---> Procederemos a guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTDq1agGAdyB"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('saved_model')\n",
    "model.save('saved_model/2_b')  #<- guardar modelo con pesos incluidos, cuidado con sobre escribir sobre modelos ya guardados\n",
    "# esta función está por deprecarse, aún así de momento está funcionando\n",
    "# existe la siguiente alternativa: 1) guardar los pesos del modelo model.save_weights(\"filepath\"), \n",
    "# 2) luego al querer cargar el modelo se debe definir la arquitectura del modelo (la misma, e.d correr solo #define architecture en 1.b.i)  \n",
    "# 3) usar model.set_weights(model.load_weights(\"filepath\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLjwWLXdAdyE"
   },
   "source": [
    "---> Verificamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFzam7SbAdyE"
   },
   "outputs": [],
   "source": [
    "model_new=tf.keras.models.load_model('saved_model/1_b_i') #<- cargar modelo\n",
    "[np.all(model_clone.get_weights()[i]==model_new.get_weights()[i]) for i in range(len(model_new.get_weights()))] # <- verificar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BRFqU2bAjwt"
   },
   "source": [
    "## 2.e Bloque $C\\times C\\times P$\n",
    "\n",
    "Una práctica usual en redes convolucionales es apilar más de un filtro convolucional antes de aplicar _pooling_. La idea detras de esto es darle más \"espacio\" a la red para aprender los patrones relevantes antes de realizar el subsampleo mediante _pooling_. En el caso de este _dataset_ también nos permite agregar más capas convolucionales sin reducir tan fuertemente la dimensión de las imagenes filtradas. Incluso muchos investigadores optan por agregar más de una capa densa el final de la red, para dar aún más libertad al modelo, pues las restricciones impuestas sobre los parámetros por la estructura convolucional parecieran restringir lo suficiente al modelo, más libertad en las capas finales no pareciera implicar un _overfitting_ tan fuerte como sería por ejemplo en una red _Fully Connected_.\n",
    "\n",
    "**Cree y entrene** una red, utilizando **dos bloques** de dos capas convolucionales y una de _maxpool_ y luego dos capas densas, es decir $C\\times C\\times P \\times C\\times C\\times P\\times D \\times D$. Utilice $128$ filtros $3\\times 3$ en las dos primeras convolucionales y $64$ filtros $3\\times 3$ en las dos siguientes. Para ambas capas de _maxpool_ utilice tamaño y _stride_ $2\\times 2$. \n",
    "\n",
    "**Comente** como se compara el desempeño con las redes anteriores. Apóyese de gráficos y valores numéricos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPzpMO-bBqqr"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oynbDNdCD7Tg"
   },
   "source": [
    "## 2.f Exploración de profundidad\n",
    "\n",
    "Por comodidad preferiremos quedarnos con la estructura en bloques del item anterior. En esta pregunta deberán explorar qué ocurre a medida uno cambia la profundidad de la red. Para esto, entrene redes con distintos números de bloques. Debe a lo menos entrenar una red por cada número de bloques entre 1 y 5 bloques (**¿Qué particularidad tiene la red con 5 bloques? ¿Puede entrenar una más profunda?**). También entrenar una red con \"0\" bloques, es decir una red densa como las de la pregunta 1. \n",
    "\n",
    "Comente sobre los casos extremos (0 bloques y 5 bloques), ya sea a partir de lo aprendido en clases o lo que observa al momento de entrenar las redes. **¿Le parece que alguno de los dos sea buena aproximación para reconocimiento de imágenes?** Para cada red recupere `history` y grafique el valor del mejor _accuracy_ en validación y el _accuracy_ sobre entrenamiento en el mismo _epoch_ en función de la profundidad de la red, similar al procedimiento realizado en 1.c.\n",
    "\n",
    "Quedan a su discreción los parámetros de cada capa convolucional, puede utilizar el número de filtros que estime convenientes, utilice _stride_ por default, y en caso de utilizar alguna regla para el número de filtros, que tal regla sea la misma para todas las profundidades (pueden ver dos posibles ejemplos en el código propuesto abajo). Para las capas de _MaxPool_ utilicen las que aparecen en el código.\n",
    "\n",
    "Para ahorrar tiempo, si observa que una red no converge, puede detener anticipadamente el entrenamiento. Para esto es recomendable usar el _Callback_ de keras `EarlyStopping` el cual deben agregar al momento de utilizar el método `.fit` (ejemplo similar en pregunta 1 y pregunta 2.d), sin embargo asegúrese de ponerle _patience_ de a lo menos 10, pues como podrá observar algunas redes empeoran su desempeño en algunas _epochs_ para luego seguir mejorando. Puede elegir monitorear la métrica que estime conveniente para esta pregunta. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rlPMIv5LGvw5"
   },
   "outputs": [],
   "source": [
    "\n",
    "for block_num # . . . \n",
    "\n",
    "    # create model\n",
    "\n",
    "    for i in range(block_num):\n",
    "        \n",
    "        model.add(Conv2D(128, (3,3),padding='same',activation='relu'))\n",
    "        model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        # or for instance\n",
    "        \n",
    "        model.add(Conv2D(int(128/(i+2)), (3,3),padding='same',activation='relu'))\n",
    "        model.add(Conv2D(int(128/(i+2)), (3,3), padding='same', activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "    # flatten\n",
    "    # dense's\n",
    "    # compile\n",
    "    # train and save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoktSPYrIDGj"
   },
   "source": [
    "## 2.g Exploración libre\n",
    "\n",
    "Como probablemente ya habrán notado, la cantidad de hiperparámetros que se pueden fijar y explorar en una red convolucional es enorme. A parte de poder modificar la arquitectura de la red y su tamaño o profundidad, pueden en cada una de las capas modificar el número de filtros, el tamaño de los filtros; modificar _stride_, cambiar las activaciones, cambiar el _padding_, cambiar los tamaños de los _MaxPool_ o sus _strides_ o incluso modificar las capas densas al final de la red. \n",
    "\n",
    "Por motivos de tiempo y con la esperanza de que la tarea no sea más tediosa de lo necesario, en vez de pedir explorar cada uno de estos parámetros, se les propone elegir una exploración de la siguiente lista. Debe realizar la exploración exahustivamente, comentar sus resultados apoyándose de gráficos y su conocimiento teórico cuando sea apropiado. Independiente de la exploración elegida debe responder las preguntas finales. \n",
    "\n",
    "Para todas las exploraciones utilice como _template_ la mejor red entrenada hasta ahora y modifique el parámetro relevante. Si utiliza otra red, justifique brévemente su elección. \n",
    "\n",
    "**Exploraciones posibles (Elija 1)**\n",
    "* Tamaño de los filtros: Manteniendo el filtro cuadrado, explore cambiar el tamaño de filtro de alguna(s) capas convolucionales. Debe explorar a lo menos valores de $1\\times 1$ hasta $9\\times 9$, por lo cual debe asegurarse realizar la exploración en una capa donde las dimensiones de los filtros de la capa anterior (o el Input de la capa) se lo permita. \n",
    "* Exploración del número de filtros: Explore variando el número de filtros de alguna(s) capas. Se recomienda explorar en potencias de 2, y debe explorar a lo menos 10 valores distintos.\n",
    "* Neuronas capa Densa: realice una exploración del número de neuronas de alguna o ambas de las capas densas. Debe explorar a lo menos 10 combinaciones distintas. Puede dejar una de las dos capas fijas y variar la otra siguiendo potencias de 2 por ejemplo. Tenga cuidado con la explosión del número de parámetros. \n",
    "* Pooling: Pruebe cambiar el tamaño de los _MaxPool_ entre $2\\times 2$ a $6\\times 6$. Pruebe también cambiando todas las capas por `AveragePooling2D`, realizando la misma exploración que con _MaxPool_.\n",
    "* Pooling \"convolucional\": Una aproximación posible para reemplazar las capas de _maxpool_ es utilizando capas convolucionales con kernel $2\\times 2$ y _stride_ $2\\times 2$. Pruebe reemplazando las capas _maxpool_ por este tipo de capas, luego pruebe una mezcla de ambas, luego pruebe simplemente eliminando las capas de _pooling_ y agregandole _stride_ a la segunda capa de cada bloque (con _kernel size_ $2\\times 2$ y $3 \\times 3$). Pruebe finalmente cambiando las funciones de activación de las capas donde se realiza la disminución de dimensión, probando a lo menos activación lineal, sigmoidea y tangente hiperbólica.\n",
    "\n",
    "**Preguntas (responder todas)**:\n",
    "* ¿A que equivaldría utilizar tamaño de kernel $1 \\times 1$?\n",
    "* ¿Por qué si cambiamos el número de filtros de una capa también modificamos el número de parámetros de la siguiente capa?\n",
    "* ¿En su opinión, qué metodo resume mejor la información de una capa, _maxpool_ o _averagepool_?\n",
    "* ¿Qué tipo de patrones esperaría usted que se extraigan mejor con un kernel no cuadrado (por ejemplo $3\\times 2$)? Apoyese de un ejemplo pequeño o una explique el fenómeno llevandolo al \"extremo\" (e.g. $1\\times 3$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szMPs_SzY3Me"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "# do it yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ommKgCnZq3h"
   },
   "source": [
    "## 2.h Data Augmentation\n",
    "\n",
    "Otra manera de evitar sobreajuste y mejorar los desempeños de una red convolucionar es usar aumentación de datos (Ignore el hecho de que botamos datos al inicio). La idea detrás de este método es un hecho muy simple: si rotamos ligeramente una foto por ejemplo de un caballo, seguirá siendo de un caballo. Lo mismo si la movemos ligeramente hacia algun lado, hacia arriba, _etc_.\n",
    "\n",
    "Keras trae implementado un generador de imagenes aumentadas, puede basarse en el código abajo para utilizarlo, aunque si lo desea o estima conveniente puede cambiar alguno de los parámetros. Entrene a completitud la mejor red que obtuvo a lo largo de toda la tarea.\n",
    "\n",
    "**Pregunta:** \n",
    "\n",
    "¿Qué tanto mejora el desempeño de la red utilizando aumentación de datos? \n",
    "\n",
    "Basándose en el abecedario de lenguaje de señas que disponemos, ¿Cree que resultará beneficioso o contraproducente realizar _flips_ horizontales y/o verticales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyRPb1q_Z4lo"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_tr)\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_tr, y_tr, batch_size=32),\n",
    "                    epochs=50,\n",
    "                    verbose=2,\n",
    "                    callbacks=[EarlyStopping(patience=5)],\n",
    "                    validation_data=(x_val,y_val),\n",
    "                    validation_freq=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_n8lFU3VcCyt"
   },
   "source": [
    "## 2.i Matriz de Confusión\n",
    "\n",
    "Si bien el _accuracy_ nos ha acompañado toda la pregunta para evaluar el desempeño de nuestras redes de forma fácilmente interpretable, no considera por ejemplo si una gran parte de los errores provienen de una sola clase, o si alguna clase se logra clasificar perfectamente. Una manera de visualizar fácilmente esta métrica más granular, es utilizando la matriz de confusión. Investigue y explique brévemente en qué consiste una matriz de confusión (puede explicar el caso binario donde solo hay dos clases).\n",
    "\n",
    "\n",
    "Luego, apoyándose en los códigos de abajo, visualizaremos la matriz de confusión del modelo que mejor se desempeñó a lo largo de toda la tarea. \n",
    "\n",
    "- ¿Algo le llama la atención? \n",
    "- ¿Qué clases se confunden más entre si?\n",
    "- ¿Coincidió esto con sus predicciones al inicio de la tarea? \n",
    "\n",
    "Igual de la misma forma que en 2.a, visualice algunas imágenes mal clasificadas por su modelo. \n",
    "- ¿Le parece razonable que el modelo no las clasifique bien?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hc_i98NicMJH"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Puede usar libreria seaborn para realizar facilmente heatmaps anotados: \n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"]=[16,8]\n",
    "# . . .\n",
    "sns.heatmap( confusion_matrix(y_val # . . . ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMJekQNEvHYm"
   },
   "source": [
    "## 2.j Batch Normalization\n",
    "Una manera propuesta de mejorar los desempeños de las redes en general, que funciona bastante bien en tareas de reconocimiento de imagenes es _Batch Normalization_. Entrene nuevamente su red preferida de la pregunta anterior, agregando capas de _Batch Normalization_ luego de cada capa de _MaxPool_. Comente sus resultados. \n",
    "\n",
    "**Preguntas**\n",
    "\n",
    "Segun su conocimiento teórico y investigación, ¿Qué realiza _Batch Normalization_ en términos matemáticos? En términos de aprendizaje, ¿qué evita la utilización de _Batch Normalization_?\n",
    "\n",
    "¿Mejoran los desempeños de la red agregando _Batch Normalization_? ¿Existe diferencias entre una capa de _batch normalization_ justo antes o justo despues de una capa de _MaxPool_ en términos numéricos? ¿Opina lo mismo en términos de aprendizaje? Discuta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NtrOx8UvN5C"
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pn-VQK6qwifz"
   },
   "source": [
    "# 3. Interpretabilidad de CNNs, transfer learning y skip connections\n",
    "\n",
    "Los modelos de aprendizaje automático, especialmente los modelos de aprendizaje profundo, a menudo se consideran una caja negra y difíciles de interpretar. Bueno, esta afirmación no es completamente cierta ni es completamente falsa. Es un hecho que depurar un modelo de aprendizaje profundo es mucho más difícil que otros modelos de aprendizaje automático, pero hay formas en las que puede obtener información sobre su modelo y, hasta cierto punto, puede ver lo que está sucediendo. Dado que trabajaremos con archivos .jpg mucho código vendrá dado, se darán ejemplos en el camino para que se familiarice con las herramientas sin la necesidad de entenderlas en su totalidad. **¡¡¡¡¡¡Evite trabajar de más y trabaje esta pregunta en _Colab_!!!!!** La gran mayoría del código de pre-procesamiento a utilizar, y ciertos tópicos ha cubrir, han sido sacados de https://www.kaggle.com/aakashnain/what-does-a-cnn-see/notebook , puede ocupar el código para guiarse, sin embargo se ha bajado el código para trabajar con tensorflow directamente. Aprecie que en los datasets de Kaggle, hay una sección notebooks, donde distintos usuarios suben distintas aplicaciones que le han dado al dataset en cuestión.  \n",
    "\n",
    "\n",
    "<h1 align='center'> <img src=\"https://miro.medium.com/max/831/1*7Ip2_SeOz_BoruHEytEMlQ.png\" width=\"60%\" height=\"60%\" /> </h1> \n",
    "<h1 align='center'></h1>\n",
    "\n",
    "Para esto analizaremos el problema de clasificación de imágenes, en este caso clasificaremos 10 especies de monos, su descripción se puede encontrar en: https://www.kaggle.com/slothkong/10-monkey-species (No es necesario descargar el dataset trabajando en _Colab_). Este dataset será el más pesado que utilizaremos en esta tarea. **Recordar usar entorno de ejecución con acelerador GPU**. Veremos los temas de transfer learning, skip connections, y class activation mappings. Donde la primera herramienta nos ayudará a hacer el entrenamiento más ligero, la segunda nos permitirá atacar tener redes profundas con pesos fijos, y la última nos permetirá visualizar qué está viendo nuestra red CNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVmCV2wKzHZX"
   },
   "source": [
    "## 3.a Carga de datos (tan solo insertar datos kaggle, leer código y comentarios para entender la funcionalidad de cada celda)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28kff3egzLoV"
   },
   "source": [
    "##### I) Iniciaremos cargando los datos. Para esto necesitará crear una cuenta en kaggle, dirigirse a su perfil, ir a Account, y en la sección API apretar _Create new API token_ , se descargará un archivo kaggle.json, ábralo como archivo de texto y obtenga su username y key. Luego ejecute el siguiente código (desconozco por qué pero a veces hay que ejecutar el código 2 veces para que funcione). Solución obtenida desde el hilo: https://gist.github.com/jayspeidell/d10b84b8d3da52df723beacc5b15cb27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXNWJ3SZw80g"
   },
   "outputs": [],
   "source": [
    "username=\"\"\n",
    "key=\"\"\n",
    "\n",
    "!pip install -q kaggle\n",
    "api_token = {\"username\":username,\"key\":key}\n",
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = str(username)\n",
    "os.environ['KAGGLE_KEY'] = str(key)\n",
    "!kaggle datasets download -d slothkong/10-monkey-species\n",
    "if not os.path.exists(\"/content/competitions/monillos\"):\n",
    "    os.makedirs(\"/content/competitions/monillos\")\n",
    "os.chdir('/content/competitions/monillos')\n",
    "for file in os.listdir():\n",
    "    if file[-4:]==\".zip\":\n",
    "      zip_ref = zipfile.ZipFile(file, 'r')\n",
    "      zip_ref.extractall()\n",
    "      zip_ref.close()\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHuXB1lo0cWu"
   },
   "source": [
    "Ejecute el siguiente código como viene para generar los conjuntos de entrenamiento y validación, en este formato la primera columna indicará el archivo .jpg al que está ligado cada dato, y la columna labels indicará a qué clase pertenece. **Si le aparece un error de directorio volver a ejecutar celda anterior**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idNhIgQXxYam"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels_dict= {'n0':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'n5':5, 'n6':6, 'n7':7, 'n8':8, 'n9':9}\n",
    "training_data = Path('training/training/') \n",
    "validation_data = Path('validation/validation/') \n",
    "labels_path = Path('monkey_labels.txt')\n",
    "# Creating a dataframe for the training dataset\n",
    "train_df = []\n",
    "for folder in os.listdir(training_data):\n",
    "    # Define the path to the images\n",
    "    imgs_path = training_data / folder\n",
    "    # Get the list of all the images stored in that directory\n",
    "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
    "    # Store each image path and corresponding label \n",
    "    for img_name in imgs:\n",
    "        train_df.append((str(img_name), labels_dict[folder]))\n",
    "train_df = pd.DataFrame(train_df, columns=['image', 'label'], index=None)\n",
    "# shuffle the dataset \n",
    "train_df = train_df.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# Creating dataframe for validation data in a similar fashion\n",
    "valid_df = []\n",
    "for folder in os.listdir(validation_data):\n",
    "    imgs_path = validation_data / folder\n",
    "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
    "    for img_name in imgs:\n",
    "        valid_df.append((str(img_name), labels_dict[folder]))\n",
    "\n",
    "        \n",
    "valid_df = pd.DataFrame(valid_df, columns=['image', 'label'], index=None)\n",
    "# shuffle the dataset \n",
    "valid_df = valid_df.sample(frac=1.).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMnmSuqj4t-1"
   },
   "source": [
    "OpenCV es una poderosa herramienta para computer vision:\n",
    "\n",
    "_OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library. OpenCV was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in the commercial products. Being a BSD-licensed product, OpenCV makes it easy for businesses to utilize and modify the code._\n",
    "\n",
    "Procederemos a visualizar una imagen del dataset al azar. Familiarícese con las f° a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UoR4rXob4zza"
   },
   "outputs": [],
   "source": [
    "# dimensions to consider for the images\n",
    "img_rows, img_cols, img_channels = 224,224,3\n",
    "\n",
    "# batch size for training  \n",
    "batch_size=8\n",
    "\n",
    "# total number of classes in the dataset\n",
    "nb_classes=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKVzSmLL3hnL"
   },
   "source": [
    "Como podrá inferir en base a la imágen mostrada, el dataset es muy pesado, por lo cual en lugar de trabajar directamente con un dataframe con los pixeles de la imágen, como en la pregunta 2, trabajaremos con la siguiente función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJ3B0S_9z2kQ"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "def data_generator(data, batch_size, is_validation_data=False):\n",
    "    # Get total number of samples in the data\n",
    "    n = len(data)\n",
    "    nb_batches = int(np.ceil(n/batch_size))\n",
    "\n",
    "    # Get a numpy array of all the indices of the input data\n",
    "    indices = np.arange(n)\n",
    "    \n",
    "    # Define two numpy arrays for containing batch data and labels\n",
    "    batch_data = np.zeros((batch_size, img_rows, img_cols, img_channels), dtype=np.float32)\n",
    "    batch_labels = np.zeros((batch_size, nb_classes), dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        if not is_validation_data:\n",
    "            # shuffle indices for the training data\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "        for i in range(nb_batches):\n",
    "            # get the next batch \n",
    "            next_batch_indices = indices[i*batch_size:(i+1)*batch_size]\n",
    "            \n",
    "            # process the next batch\n",
    "            for j, idx in enumerate(next_batch_indices):\n",
    "                img = cv2.imread(data.iloc[idx][\"image\"])\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                label = data.iloc[idx][\"label\"]\n",
    "                img = cv2.resize(img, (img_rows, img_cols)).astype(np.float32)\n",
    "                batch_data[j] = img\n",
    "                batch_labels[j] = to_categorical(label,num_classes=nb_classes)\n",
    "            \n",
    "            batch_data = preprocess_input(batch_data)\n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxnbZk1z2fj6"
   },
   "outputs": [],
   "source": [
    "#training data generator \n",
    "train_data_gen = data_generator(train_df, batch_size)\n",
    "\n",
    "# validation data generator \n",
    "valid_data_gen = data_generator(valid_df, batch_size, is_validation_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfIk38eEiYiQ"
   },
   "source": [
    "##### II) Visualice una imágen para cada clase de mono indicado su raza. Básese en el siguiente código.\n",
    "\n",
    "OpenCV es una poderosa herramienta para computer vision:\n",
    "\n",
    "_OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library. OpenCV was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in the commercial products. Being a BSD-licensed product, OpenCV makes it easy for businesses to utilize and modify the code._\n",
    "\n",
    "Procederemos a visualizar una imagen del dataset al azar. Familiarícese con las f° a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgK5MkaoigQ5"
   },
   "outputs": [],
   "source": [
    "idx= np.random.randint(100) # <- random number\n",
    "sample_image = cv2.imread(valid_df.iloc[idx]['image']) #read image from validation set\n",
    "sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB) #set color\n",
    "sample_image = cv2.resize(sample_image, (img_rows, img_cols)) #resize, because .jpg images are from diferent size\n",
    "sample_label = valid_df.iloc[idx][\"label\"] #get label\n",
    "sample_image_processed = np.expand_dims(sample_image, axis=0) #not used here, but to transform image from (pixel,pixel,canal) to (obs, pixel, pixel, canal)\n",
    "sample_image_processed = preprocess_input(sample_image_processed) #transformation for vgg16\n",
    "plt.title(\"asdasasdasd\")\n",
    "plt.imshow(sample_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83lRdlA3-FlU"
   },
   "source": [
    "## 3.b Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sDrs7ng-FVs"
   },
   "source": [
    "El aprendizaje por transferencia es un método de aprendizaje automático en el que un modelo desarrollado para una tarea se reutiliza como punto de partida para un modelo en una segunda tarea.\n",
    "\n",
    "Es un enfoque popular en el aprendizaje profundo en el que los modelos previamente entrenados se utilizan como punto de partida en la visión por computadora y las tareas de procesamiento del lenguaje natural, dada la gran cantidad de recursos informáticos y de tiempo necesarios para desarrollar modelos de redes neuronales sobre estos problemas y los enormes saltos en las habilidades que proporcionan sobre problemas relacionados. El concepto de transfer learning abarca más que este tipo de implementación en específico, p.ej, en el área de reinforcement learning se le puede llamar transfer learning al hecho de utilizar demostraciones humanas para ayudar a una red neuronal a resolver un _task_ o _multi-task_ en específico.\n",
    "\n",
    "<h1 align='center'> <img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png\" width=\"60%\" height=\"60%\" /> </h1> \n",
    "<h1 align='center'> VGG16 </h1> \n",
    "\n",
    "Para este item utilizaremos la red vgg16 como red base (info: https://neurohive.io/en/popular-networks/vgg16/) desarrollada por Oxford."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoXvIUbyAjlG"
   },
   "source": [
    "##### I) Procederemos a obtener la red VGG16 desde keras.applications, retirar su arquitectura densa, congelar sus pesos, y añadir una capa densa propia entrenable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vR3YrzNp-EkQ"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dropout,Dense,Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import History, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "tf.keras.backend.clear_session()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "base_model = VGG16(input_shape=(img_rows, img_cols, img_channels), weights='imagenet', include_top=True)\n",
    "#  get the output of the last layer\n",
    "base_model_output = base_model.layers[-2].output\n",
    "# # add new layers \n",
    "x = Dropout(0.7)(base_model_output)\n",
    "output = Dense(10, activation='softmax')(x)\n",
    "# define a new model \n",
    "model = tf.keras.models.Model(base_model.input, output)\n",
    "# # Freeze all the base model layers\n",
    "for layer in base_model.layers[:-1]:\n",
    "    layer.trainable=False\n",
    "my_callbacks = [History(), # Returns validation and training loss\n",
    "    EarlyStopping(patience=2,monitor=\"val_accuracy\", #Stops training when the validation loss doesnt get better in n°patience consecutive epochs\n",
    "                                     restore_best_weights=True)]\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZbVzMBtGiVM"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAaTQbI8B0nW"
   },
   "outputs": [],
   "source": [
    "# number of training and validation steps for training and validation\n",
    "nb_train_steps = int(np.ceil(len(train_df)/batch_size))\n",
    "nb_valid_steps = int(np.ceil(len(valid_df)/batch_size))\n",
    "# number of epochs \n",
    "nb_epochs=3\n",
    "\n",
    "hist = model.fit(train_data_gen,      # ¿Demasiado lento?, revisar estar usando entorno de ejecución en modo GPU. Debiese demorarse aprox. 40 secs por epoch. Dejar verbose\n",
    "                                          # para seguir el entrenamiento, esto tomará su tiempo en comparación con las demás secciones.\n",
    "                              epochs=nb_epochs, \n",
    "                              steps_per_epoch=nb_train_steps, \n",
    "                              validation_data=valid_data_gen, \n",
    "                              validation_steps=nb_valid_steps,\n",
    "                              callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5bGkyuOKRfe"
   },
   "source": [
    "##### II) Grafique los errores y accuracy de entrenamiento y validación a lo largo de los epochs. **Comente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSbCuaOQKYi-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXZoO_lzEwZ3"
   },
   "source": [
    "Para evitar reentrenar redes al reconectarse, la red neuronal entrenada se puede guardar (arquitectura, pesos, y configuración de entrenamiento) del siguiente modo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xw_rImSVExIO"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('saved_model')\n",
    "model.save('saved_model/3_b_i') #guardar\n",
    "# model=tf.keras.models.load_model('saved_model/3_b_i/') #<- cargar modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEb3sfX3LYXu"
   },
   "source": [
    "##### III) **(Las preguntas de este ítem 2.b se tendrán que volver a implementar para futuras preguntas)** \n",
    "\n",
    "Realice la visualización del input (con título predicted label y true label), Class Activation Map (con título del label y salida de la red correspondiente), y superposición de input y CAM correspondiente al predicted label. **Deberá** modificar el código para obtener lo solicitado para 10 entradas distintas (1 para cada clase de mono) y su CAM para cada una de las 10 clases de monos. En total para cada clase de mono deberá obtener: 1 imágen de entrada de la clase de mono en cuestión, 10 CAM una para cada neurona del output de la red, y 1 superposición de la imágen de entrada y el CAM correspondiente a la predicción (por lo tanto, 120 imágenes en total). **Las imágenes tienen que ser claras, cada una de tamaño semejante a las que entrega el siguiente código.** Ocupe su herramienta gráfica preferida.\n",
    "\n",
    "Apoyándose de las visualizaciones responda todas las preguntas siguientes:\n",
    "\n",
    "**1) ¿Qué es CAM?, ¿Cómo nos ayuda a entender la visualización de nuestra CNN?** Puede limitarse a responder con la información entregada en el artículo https://medium.com/@GaganaB/class-activation-maps-551477720679 (si es que se le acabaron las visitas a medium, puede entrar en modo incógnito de manera ilimitada) y en el video https://www.youtube.com/watch?v=vTY58-51XZA&ab_channel=LazyProgrammer\n",
    "\n",
    "**2) ¿Dónde se enfoca la red para verificar a qué clase de mono pertenece la imágen? ¿Qué estrategia asume la red para reconocer cada clase de mono?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNPSDirSMxhl"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"]=[20,8]\n",
    "from keras import backend as K\n",
    "\n",
    "# get random image, true label, and predicted label\n",
    "idx= np.random.randint(100) # <- random number\n",
    "true_label=valid_df.iloc[idx]['label']\n",
    "\n",
    "\n",
    "####### VISUALIZACIÓN INPUT\n",
    "sample_image = cv2.imread(valid_df.iloc[idx]['image'])\n",
    "sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
    "sample_image = cv2.resize(sample_image, (img_rows, img_cols))\n",
    "sample_label = valid_df.iloc[idx][\"label\"]\n",
    "sample_image_processed = np.expand_dims(sample_image, axis=0)\n",
    "sample_image_processed = preprocess_input(sample_image_processed)\n",
    "predicted_label=np.argmax(model.predict(sample_image_processed), axis=-1)[0]\n",
    "plt.subplot(1,4,1)\n",
    "plt.title(\"Predicted label: \"+str(predicted_label)+\"\\n True label: \"+str(true_label))\n",
    "plt.imshow(sample_image)# <- Image is ready to plot\n",
    "\n",
    "##### Visualización CAM\n",
    "heatmaps=[]\n",
    "kk=0\n",
    "predicted_label=np.argmax(model.predict(sample_image_processed), axis=-1)[0] #repeated for clearness\n",
    "for k in [0,predicted_label]:\n",
    "  predicted_output = model.output[:, k]\n",
    "  # choose the last conv layer in your model\n",
    "  last_conv_layer = model.get_layer('block5_conv3') #<....... you'll need to look what's the name of the last conv model.summary())\n",
    "  grads = K.gradients(predicted_output, last_conv_layer.output)[0] #predicted output=loss, last_conv_layer=input al gradiente, ¿qué calculará el gradiente entonces?\n",
    "  # take mean gradient per feature map\n",
    "  grads = K.mean(grads, axis=(0,1,2))\n",
    "  # Define a function that generates the values for the output and gradients\n",
    "  evaluation_function = K.function([model.input], [grads, last_conv_layer.output[0]]) #en eager executions disabled estamos trabajando con tensores continuamente, \n",
    "                                                                                      # si siguen el código se darán cuenta que evaluation function mantiene \n",
    "                                                                                      # las definiciones de variables\n",
    "  # get the values\n",
    "  grads_values, conv_ouput_values = evaluation_function([sample_image_processed]) #run evaluation function\n",
    "  # iterate over each feature map in yout conv output and multiply\n",
    "  # the gradient values with the conv output values. This gives an \n",
    "  # indication of \"how important a feature is\"\n",
    "  for i in range(conv_ouput_values.shape[-1]): # we have 512 features in our last conv layer\n",
    "      conv_ouput_values[:,:,i] *= grads_values[i]\n",
    "  # create a heatmap\n",
    "  heatmap = np.mean(conv_ouput_values, axis=-1)\n",
    "  # remove negative values\n",
    "  heatmap = np.maximum(heatmap, 0)\n",
    "  # re-scale\n",
    "  heatmap /= heatmap.max()\n",
    "  # get the heatmap for class activation map(CAM)\n",
    "  heatmap = cv2.resize(heatmap, (sample_image.shape[0], sample_image.shape[1]))\n",
    "  heatmap = heatmap *255\n",
    "  heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\n",
    "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "  plt.subplot(1,4,2+kk)\n",
    "  plt.title(\"CAM for class:\"+ str(k)+\"\\n output:\"+str(np.round(model.predict(sample_image_processed)[0,k],2)*100)+\"%\")\n",
    "  plt.imshow(heatmap)# <- Image is ready to plot\n",
    "  kk+=1\n",
    "  heatmaps.append(heatmap) # <- correct it\n",
    "# get the superimposed image\n",
    "super_imposed_image = heatmaps[1] * 0.5 + sample_image #<- correct it  \n",
    "super_imposed_image = np.clip(super_imposed_image, 0,255).astype(np.uint8)\n",
    "plt.subplot(1,4,4)\n",
    "plt.title(\"Superimposed image\")\n",
    "plt.imshow(super_imposed_image)# <- Image is ready to plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RK-Z8E15wa-Q"
   },
   "source": [
    "##### IV) **(Las preguntas de este ítem 2.b se tendrán que volver a implementar para futuras preguntas)** Visualice los feature maps de **todas** las capas convolucionales del modelo para una entrada de su elección (mantenga el id de esta imágen para cuando tenga que visualizar nuevamente en 3.c y 3.d). Apóyese en el siguiente código que las genera para la primera capa. \n",
    "\n",
    "**Pregunta:** ¿Cómo se relaciona esta información respecto a lo que nos entrega CAM? ¿Qué feature map ocupa CAM para construirse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1F-i23axTjx"
   },
   "outputs": [],
   "source": [
    "# get random image, SELECCIONE UNA A GUSTO\n",
    "idx= np.random.randint(100) # <- random number\n",
    "true_label=valid_df.iloc[idx]['label']\n",
    "####### VISUALIZACIÓN INPUT\n",
    "sample_image = cv2.imread(valid_df.iloc[idx]['image'])\n",
    "sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
    "sample_image = cv2.resize(sample_image, (img_rows, img_cols))\n",
    "sample_label = valid_df.iloc[idx][\"label\"]\n",
    "sample_image_processed = np.expand_dims(sample_image, axis=0)\n",
    "sample_image_processed = preprocess_input(sample_image_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qcx4VRI_YrQh"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "def get_n_layers(max_layer, original_model):\n",
    "  truncated_model = Sequential()\n",
    "  for layer in range(max_layer): #first is the input\n",
    "    truncated_model.add(original_model.get_layer(index=layer))\n",
    "  truncated_model.summary()\n",
    "  return truncated_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hKWtFceYLdD"
   },
   "outputs": [],
   "source": [
    "vis_model=get_n_layers(2,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMAj41WLVCsJ"
   },
   "outputs": [],
   "source": [
    "fet_maps_stacked=vis_model.predict(sample_image_processed)[0,:,:,:]\n",
    "feature_maps=np.zeros((224*8,224*8))\n",
    "k=0\n",
    "for i in range(8):\n",
    "  for j in range(8):\n",
    "      feature_map = fet_maps_stacked[:,:,k]\n",
    "      feature_map -= feature_map.mean()\n",
    "      feature_map /= feature_map.std()\n",
    "      feature_map *=255\n",
    "      feature_map = np.clip(feature_map, 0, 255).astype(np.uint8)\n",
    "      feature_maps[224*i:224*(i+1),224*j:224*(j+1)]=feature_map\n",
    "      k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7Pm88Tjytif"
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Predicted label: \"+str(np.argmax(model.predict(sample_image_processed), axis=-1)[0])+\"\\n True label: \"+str(true_label))\n",
    "plt.imshow(sample_image)# <- Image is ready to plot\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(feature_maps)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkPaxu8w39Fg"
   },
   "source": [
    "## 3.c Transfer learning parte II\n",
    "I) **Repetir los puntos I) a IV) de la sección anterior** usando como red base VGG19 (Si es que desea utilizar otra no hay problema, visitar: https://keras.io/api/applications/). Para la visualización de CAM y feature maps, use las mismas imágenes de entrada para mejor comparación.\n",
    "\n",
    "\n",
    "**A partir de los resultados responda: ¿Cómo cambió la estrategia de esta red respecto a la del punto anterior?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvBzRJQU4Vo-"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "tf.keras.backend.clear_session()\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50lHKeMDqG6G"
   },
   "source": [
    "II) III) IV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8r_I1FGE0S1"
   },
   "source": [
    "## 3.d CNN con skip connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rF52-AH57Ox"
   },
   "source": [
    "Otra manera de mejorar los resultados de las redes, sobretodo de las redes profundas donde se observa el problema de _vanishing gradient_ son las relativamente nuevas _skip connections_ o redes residuales. En vez de preocuparse de cómo manejar los pesos de la red para permitir que el gradiente no explote o no desaparezca, se permite al gradiente \"pasar\" sin ser modificado, agregando conecciones con pesos fijos entre capas de distintas profundidades, en la práctica permitiendo a la señar \"saltarse\" las capas intermedias. Esta idea ha permitido desarrollos como los de ResNet, llegando a profundidades de cientos de capas y aún logrando aprendizaje. \n",
    "\n",
    "Basandose en el código mostrado abajo, implemente una ResNet de su gusto. _Tip: Utilice BatchNormalization después de cada capa convolucional._\n",
    "\n",
    "**Obtenga un error de validación superior al 50%**. _No tenga miedo de subir la profundidad, pero sí de la cantidad de hiperparámetros a entrenar, checkear model.summary()_\n",
    "\n",
    "**Repita los pasos II) a IV) de las secciones anteriores. Comente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gL6tboCPFsXc"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, concatenate\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import History, EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "tf.keras.backend.clear_session()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "x = Input(shape=(img_rows, img_cols, img_channels))\n",
    "\n",
    "y = Conv2D(64, (3,3),padding='same',activation='relu')(x)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(64, (3,3),padding='same',activation='relu')(y)\n",
    "y = BatchNormalization()(y)\n",
    "z = concatenate([x, y])\n",
    "\n",
    "z = MaxPooling2D(pool_size=(2, 2))(z)\n",
    "\n",
    "y = Conv2D(64, (3,3),padding='same',activation='relu')(z)\n",
    "y = BatchNormalization()(y)\n",
    "y = Conv2D(64, (3,3),padding='same',activation='relu')(y)\n",
    "y = BatchNormalization()(y)\n",
    "z = concatenate([z, y])\n",
    "\n",
    "# . . .\n",
    "\n",
    "\n",
    "# . . . \n",
    "\n",
    "z = Flatten()(z)\n",
    "z = Dense(256 + 64, activation='relu')(z)\n",
    "z = BatchNormalization()(z)\n",
    "out = Dense(10, activation='softmax')(z)\n",
    "\n",
    "res_mod = tf.keras.models.Model(x,out)\n",
    "\n",
    "my_callbacks = [History(), # Returns validation and training loss\n",
    "    EarlyStopping(patience=2,monitor=\"val_accuracy\", #Stops training when the validation loss doesnt get better in n°patience consecutive epochs,keep it at 100 it's only to show u\n",
    "                                     restore_best_weights=True)]\n",
    "\n",
    "\n",
    "optimizer = RMSprop(0.001)\n",
    "res_mod.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "# summary\n",
    "res_mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fJ8cDPrGA9N"
   },
   "outputs": [],
   "source": [
    "# number of training and validation steps for training and validation\n",
    "nb_train_steps = int(np.ceil(len(train_df)/batch_size))\n",
    "nb_valid_steps = int(np.ceil(len(valid_df)/batch_size))\n",
    "# number of epochs \n",
    "nb_epochs=10 # si no obtuvo el resultado deseado en 10 epochs \n",
    "\n",
    "hist = res_mod.fit(train_data_gen,      # ¿Demasiado lento?, revisar estar usando entorno de ejecución en modo GPU. Debiese demorarse aprox. 40 secs por epoch. Dejar verbose\n",
    "                                          # para seguir el entrenamiento, esto tomará su tiempo en comparación con las demás secciones.\n",
    "                              epochs=nb_epochs, \n",
    "                              steps_per_epoch=nb_train_steps, \n",
    "                              validation_data=valid_data_gen, \n",
    "                              validation_steps=nb_valid_steps,\n",
    "                              callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mc4-7BD5qNy4"
   },
   "source": [
    "II) III) IV)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tarea1_completa.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
